{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFiCyWQ-NC5D"
   },
   "source": [
    "# Ungraded Lab: Multiple LSTMs\n",
    "\n",
    "In this lab, you will look at how to build a model with multiple LSTM layers. Since you know the preceding steps already (e.g. downloading datasets, preparing the data, etc.), we won't expound on it anymore so you can just focus on the model building code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeGliUKn-44h"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7mnIF-4FnzmG"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqmDNHeByJqr"
   },
   "source": [
    "## Load and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AW-4Vo4TMUHb"
   },
   "outputs": [],
   "source": [
    "# The dataset is already downloaded for you. For downloading you can use the code below.\n",
    "imdb = tfds.load(\"imdb_reviews\", as_supervised=True, data_dir=\"../data/\", download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UpAGm8UQnZdV"
   },
   "outputs": [],
   "source": [
    "# Extract the train reviews and labels\n",
    "train_reviews = imdb['train'].map(lambda review, label: review)\n",
    "train_labels = imdb['train'].map(lambda review, label: label)\n",
    "\n",
    "# Extract the test reviews and labels\n",
    "test_reviews = imdb['test'].map(lambda review, label: review)\n",
    "test_labels = imdb['test'].map(lambda review, label: label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lvm4ZwdPndhS"
   },
   "outputs": [],
   "source": [
    "# Download the subword vocabulary (not needed in Coursera)\n",
    "# !wget -nc https://storage.googleapis.com/tensorflow-1-public/course3/imdb_vocab_subwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3VOghFmInfdY"
   },
   "outputs": [],
   "source": [
    "# Initialize the subword tokenizer\n",
    "subword_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary='./imdb_vocab_subwords.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF8bUh_5Ff7y"
   },
   "source": [
    "Like the previous lab, we increased the `BATCH_SIZE` here to make the training faster. If you are doing this on your local machine and have a powerful processor, feel free to use the value used in the lecture (i.e. 64) to get the same results as Laurence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ffvRUI0_McDS"
   },
   "outputs": [],
   "source": [
    "# Data pipeline and padding parameters\n",
    "SHUFFLE_BUFFER_SIZE = 10000\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 256\n",
    "PADDING_TYPE = 'pre'\n",
    "TRUNC_TYPE = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R1DVetUinjks"
   },
   "outputs": [],
   "source": [
    "def padding_func(sequences):\n",
    "  '''Generates padded sequences from a tf.data.Dataset'''\n",
    "\n",
    "  # Put all elements in a single ragged batch\n",
    "  sequences = sequences.ragged_batch(batch_size=sequences.cardinality())\n",
    "\n",
    "  # Output a tensor from the single batch\n",
    "  sequences = sequences.get_single_element()\n",
    "\n",
    "  # Pad the sequences\n",
    "  padded_sequences = tf.keras.utils.pad_sequences(sequences.numpy(), \n",
    "                                                  truncating=TRUNC_TYPE, \n",
    "                                                  padding=PADDING_TYPE\n",
    "                                                 )\n",
    "\n",
    "  # Convert back to a tf.data.Dataset\n",
    "  padded_sequences = tf.data.Dataset.from_tensor_slices(padded_sequences)\n",
    "\n",
    "  return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NG3unVVFnnJ8"
   },
   "outputs": [],
   "source": [
    "# Generate integer sequences using the subword tokenizer\n",
    "train_sequences_subword = train_reviews.map(lambda review: subword_tokenizer.tokenize(review)).apply(padding_func)\n",
    "test_sequences_subword = test_reviews.map(lambda review: subword_tokenizer.tokenize(review)).apply(padding_func)\n",
    "\n",
    "# Combine the integer sequence and labels\n",
    "train_dataset_vectorized = tf.data.Dataset.zip(train_sequences_subword,train_labels)\n",
    "test_dataset_vectorized = tf.data.Dataset.zip(test_sequences_subword,test_labels)\n",
    "\n",
    "# Optimize the datasets for training\n",
    "train_dataset_final = (train_dataset_vectorized\n",
    "                       .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                       .cache()\n",
    "                       .prefetch(buffer_size=PREFETCH_BUFFER_SIZE)\n",
    "                       .batch(BATCH_SIZE)\n",
    "                       )\n",
    "\n",
    "test_dataset_final = (test_dataset_vectorized\n",
    "                      .cache()\n",
    "                      .prefetch(buffer_size=PREFETCH_BUFFER_SIZE)\n",
    "                      .batch(BATCH_SIZE)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcZEiG9ayNZr"
   },
   "source": [
    "## Build and Compile the Model\n",
    "\n",
    "You can build multiple layer LSTM models by simply appending another `LSTM` layer in your `Sequential` model and enabling the `return_sequences` flag to `True`. This is because an `LSTM` layer expects a sequence input so if the previous layer is also an LSTM, then it should output a sequence as well. See the code cell below that demonstrates this flag in action. You'll notice that the output dimension is in 3 dimensions `(batch_size, timesteps, features)` when `return_sequences` is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "18MsI2LU75kH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 1\n",
      "timesteps (sequence length): 20\n",
      "features (embedding size): 16\n",
      "lstm output units: 8\n",
      "shape of input array: (1, 20, 16)\n",
      "shape of lstm output(return_sequences=False): (1, 8)\n",
      "shape of lstm output(return_sequences=True): (1, 20, 8)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 1\n",
    "TIMESTEPS = 20\n",
    "FEATURES = 16\n",
    "LSTM_DIM = 8\n",
    "\n",
    "print(f'batch_size: {BATCH_SIZE}')\n",
    "print(f'timesteps (sequence length): {TIMESTEPS}')\n",
    "print(f'features (embedding size): {FEATURES}')\n",
    "print(f'lstm output units: {LSTM_DIM}')\n",
    "\n",
    "# Define array input with random values\n",
    "random_input = np.random.rand(BATCH_SIZE,TIMESTEPS,FEATURES)\n",
    "print(f'shape of input array: {random_input.shape}')\n",
    "\n",
    "# Define LSTM that returns a single output\n",
    "lstm = tf.keras.layers.LSTM(LSTM_DIM)\n",
    "result = lstm(random_input)\n",
    "print(f'shape of lstm output(return_sequences=False): {result.shape}')\n",
    "\n",
    "# Define LSTM that returns a sequence\n",
    "lstm_rs = tf.keras.layers.LSTM(LSTM_DIM, return_sequences=True)\n",
    "result = lstm_rs(random_input)\n",
    "print(f'shape of lstm output(return_sequences=True): {result.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Was3BX6_50C"
   },
   "source": [
    "The next cell implements the stacked LSTM architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VPNwU1SVyTjm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">488,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m488,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m24,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">526,017</span> (2.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m526,017\u001b[0m (2.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">526,017</span> (2.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m526,017\u001b[0m (2.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model parameters\n",
    "EMBEDDING_DIM = 64\n",
    "LSTM1_DIM = 32\n",
    "LSTM2_DIM = 16\n",
    "DENSE_DIM = 64\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(None,)),\n",
    "    tf.keras.layers.Embedding(subword_tokenizer.vocabulary_size(), EMBEDDING_DIM),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM1_DIM, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM2_DIM)),\n",
    "    tf.keras.layers.Dense(DENSE_DIM, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Uip7QOVzMoMq"
   },
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh39GlZP79DY"
   },
   "source": [
    "## Train the Model\n",
    "\n",
    "The additional LSTM layer will lengthen the training time compared to the previous lab. Given the default parameters, it will take around 2 minutes per epoch in your lab environment. Also, since this is a larger model, it might start to overfit quickly so you may want to use fewer epochs or use a callback to monitor the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7mlgzaRDMtF6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_1/bidirectional_1_2/backward_lstm_3_1/CudnnRNNV3 defined at (most recent call last):\n  File \"/usr/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n\n  File \"/usr/lib/python3.11/runpy.py\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_1203/2119093684.py\", line 4, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 51, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\", line 209, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 202, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/function.py\", line 155, in _run_through_graph\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 592, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py\", line 221, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/lstm.py\", line 560, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py\", line 406, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/lstm.py\", line 527, in inner_loop\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 841, in lstm\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 933, in _cudnn_lstm\n\nFailed to call DoRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 16, 1, 4008, 256, 16] \n\t [[{{node sequential_1/bidirectional_1_2/backward_lstm_3_1/CudnnRNNV3}}]] [Op:__inference_one_step_on_iterator_6437]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset_final\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node sequential_1/bidirectional_1_2/backward_lstm_3_1/CudnnRNNV3 defined at (most recent call last):\n  File \"/usr/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n\n  File \"/usr/lib/python3.11/runpy.py\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_1203/2119093684.py\", line 4, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 51, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\", line 209, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 202, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/function.py\", line 155, in _run_through_graph\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 592, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py\", line 221, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\", line 846, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\", line 48, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/lstm.py\", line 560, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py\", line 406, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/lstm.py\", line 527, in inner_loop\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 841, in lstm\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 933, in _cudnn_lstm\n\nFailed to call DoRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 16, 1, 4008, 256, 16] \n\t [[{{node sequential_1/bidirectional_1_2/backward_lstm_3_1/CudnnRNNV3}}]] [Op:__inference_one_step_on_iterator_6437]"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset_final, epochs=NUM_EPOCHS, validation_data=test_dataset_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Mp1Z7P9pYRSK"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m   ax[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m     25\u001b[0m   plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 27\u001b[0m plot_loss_acc(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_loss_acc(history):\n",
    "  '''Plots the training and validation loss and accuracy from a history object'''\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "  ax[0].plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "  ax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "  ax[0].set_title('Training and validation accuracy')\n",
    "  ax[0].set_xlabel('epochs')\n",
    "  ax[0].set_ylabel('accuracy')\n",
    "  ax[0].legend()\n",
    "\n",
    "  ax[1].plot(epochs, loss, 'bo', label='Training Loss')\n",
    "  ax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "  ax[1].set_title('Training and validation loss')\n",
    "  ax[1].set_xlabel('epochs')\n",
    "  ax[1].set_ylabel('loss')\n",
    "  ax[1].legend()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txQdN63vBlTK"
   },
   "source": [
    "## Wrap Up\n",
    "\n",
    "This lab showed how you can build deep networks by stacking LSTM layers. In the next labs, you will continue exploring other architectures you can use to implement your sentiment classification model. \n",
    "\n",
    "As before, run the cell below to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shutdown the kernel to free up resources. \n",
    "# Note: You can expect a pop-up when you run this cell. You can safely ignore that and just press `Ok`.\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "k = get_ipython().kernel\n",
    "\n",
    "k.do_shutdown(restart=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "C3_W3_Lab_2_multiple_layer_LSTM.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
